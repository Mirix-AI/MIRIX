agent_name: mirix
model_name: gemini-2.0-flash
# Ollama support - uncomment to use Ollama instead
# model_name: qwen3-vl:235b-cloud
# model_endpoint_type: ollama
# model_endpoint: http://localhost:11434/v1
# context_window: 16384
# put_inner_thoughts_in_kwargs: true
is_screen_monitor: true